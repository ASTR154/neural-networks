{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Dyw4pbps6_9"
      },
      "source": [
        "# Classify Handwritten Digits with Convolutional Neural Networks (CNNs)\n",
        "By B Nord (2018 Nov 09)  \n",
        "Minor updates by G Hosseinzadeh (2025 May 19)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JYuP1qqMpyHZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzY9nK-_LLC6"
      },
      "source": [
        "## Prepare the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ppacy9UTzAJT"
      },
      "source": [
        "### Download the data\n",
        "Load the [MNIST](https://en.wikipedia.org/wiki/MNIST_database) data set included in Keras. This consists of handwritten digits from 0-9 that we will try to identify with a CNN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qwXuui6_yYBv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "# uncomment the following line if the load_data function crashes with SSL: CERTIFICATE_VERIFY_FAILED\n",
        "# !curl https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz -o ~/.keras/datasets/mnist.npz\n",
        "\n",
        "(x_train_temp, y_train_temp), (x_test_temp, y_test_temp) = keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5 0 4 ... 5 6 8]\n"
          ]
        }
      ],
      "source": [
        "print(y_train_temp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asIjm01UzUiK"
      },
      "source": [
        "### **Look** at the data\n",
        "Check whether the shapes of 'data' and 'label' (for train and test, respectively) match. If they don't now, Keras/TF will kindly yell at you later. (You always do this so that you **know** what the structure is!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5L507V2Ayk3y"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Data Shape: (60000, 28, 28)\n",
            "Test Data Shape: (10000, 28, 28)\n",
            "Train Label Shape: (60000,)\n",
            "Test Label Shape: (10000,)\n"
          ]
        }
      ],
      "source": [
        "print(\"Train Data Shape:\", x_train_temp.shape)\n",
        "print(\"Test Data Shape:\", x_test_temp.shape)\n",
        "print(\"Train Label Shape:\", y_train_temp.shape)\n",
        "print(\"Test Label Shape:\", y_test_temp.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SquIrP2E0Pnz"
      },
      "source": [
        "Print out an example image and label from in the training set. Can you see the pattern of the number? Plot the first two images in the set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "p9sOE3TI4nHR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5 0\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(y_train_temp[0], y_train_temp[1])\n",
        "\n",
        "fig, ax = plt.subplots(1, 2)\n",
        "ax[0].imshow(x_train_temp[0])\n",
        "ax[0].set_title(y_train_temp[0])\n",
        "ax[1].imshow(x_train_temp[1])\n",
        "ax[1].set_title(y_train_temp[1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnva-KuHjLw0"
      },
      "source": [
        "### Prepare the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPVp8HLR4LzC"
      },
      "source": [
        "Data often need to be reshaped and normalized for ingestion into the neural network.\n",
        "Add an extra (empty) dimension to the end of the images (see `np.expand_dims`).\n",
        "Normalize the pixel values to be between 0 and 1 for the network.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "vTCyohBf4Nhp"
      },
      "outputs": [],
      "source": [
        "x_train = np.expand_dims(x_train_temp, 3)\n",
        "x_test = np.expand_dims(x_test_temp, 3)\n",
        "x_train= np.divide(x_train, x_train.max(1).max(1)[0])\n",
        "x_test= np.divide(x_test, x_test.max(1).max(1)[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aTWoi_E6Ueh"
      },
      "source": [
        "Apply *one-hot encoding* to the labels.\n",
        "\n",
        "\n",
        "1.   The current encoding provides a literal label. For example, the label for \"3\"  is `3`.\n",
        "2.   One-hot encoding places a \"1\" in an array at the appropriate location for that datum. For example, the label \"3\" becomes `[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]`.\n",
        "\n",
        "This increases the efficiency of the matrix algebra during network training and evaluation.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "GIWLxZN099Bl"
      },
      "outputs": [],
      "source": [
        "y_train = keras.utils.to_categorical(y_train_temp)\n",
        "y_test = keras.utils.to_categorical(y_test_temp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PO2kozw-czq"
      },
      "source": [
        "## Design Neural Network Architecture!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po6px0oM-vdg"
      },
      "source": [
        "### Select model format and add layers to the model sequentially\n",
        "Create a sequential model with the following layers:\n",
        "1. input layer with the shape of one of the input images\n",
        "2. 2D convolution layer with 32 filters, a kernel size of (3, 3), and a ReLU activation function\n",
        "3. dropout layer with a rate of 0.25 and a ReLU activation function\n",
        "4. flattening layer\n",
        "5. fully connected (dense) layer with a neuron for each convolution filter\n",
        "6. dropout layer with a rate of 0.5\n",
        "7. output fully connected (dense) layer with a neuron for each classification and a softmax activation function\n",
        "\n",
        "Print out the model summary table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "-apTS3Fyrc2B"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Unrecognized keyword arguments passed to Dropout: {'activation': 'relu'}",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m inputs = keras.Input(shape=(\u001b[32m28\u001b[39m,\u001b[32m28\u001b[39m,\u001b[32m1\u001b[39m))\n\u001b[32m      2\u001b[39m convolution = keras.layers.Convolution2D(filters=\u001b[32m32\u001b[39m, kernel_size=\u001b[32m3\u001b[39m, activation=\u001b[33m'\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m'\u001b[39m)(inputs)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m dropout = \u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrate\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.24\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrelu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m(convolution)\n\u001b[32m      4\u001b[39m flattening = keras.layers.Flatten()(dropout)\n\u001b[32m      5\u001b[39m dense = keras.layers.Dense(units=\u001b[32m32\u001b[39m)(flattening)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tobyh\\Documents\\School\\ASTR\\ASTR 154\\data_venv_312\\Lib\\site-packages\\keras\\src\\layers\\regularization\\dropout.py:42\u001b[39m, in \u001b[36mDropout.__init__\u001b[39m\u001b[34m(self, rate, noise_shape, seed, **kwargs)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, rate, noise_shape=\u001b[38;5;28;01mNone\u001b[39;00m, seed=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[32m0\u001b[39m <= rate <= \u001b[32m1\u001b[39m:\n\u001b[32m     44\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     45\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid value received for argument \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     46\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m`rate`. Expected a float value between 0 and 1. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     47\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mReceived: rate=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrate\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     48\u001b[39m         )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tobyh\\Documents\\School\\ASTR\\ASTR 154\\data_venv_312\\Lib\\site-packages\\keras\\src\\layers\\layer.py:291\u001b[39m, in \u001b[36mLayer.__init__\u001b[39m\u001b[34m(self, activity_regularizer, trainable, dtype, autocast, name, **kwargs)\u001b[39m\n\u001b[32m    289\u001b[39m     \u001b[38;5;28mself\u001b[39m._input_shape_arg = input_shape_arg\n\u001b[32m    290\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[32m--> \u001b[39m\u001b[32m291\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    292\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUnrecognized keyword arguments \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    293\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mpassed to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    294\u001b[39m     )\n\u001b[32m    296\u001b[39m \u001b[38;5;28mself\u001b[39m._path = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Will be determined in `build_wrapper`\u001b[39;00m\n\u001b[32m    297\u001b[39m \u001b[38;5;28mself\u001b[39m.built = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "\u001b[31mValueError\u001b[39m: Unrecognized keyword arguments passed to Dropout: {'activation': 'relu'}"
          ]
        }
      ],
      "source": [
        "inputs = keras.Input(shape=(28,28,1))\n",
        "convolution = keras.layers.Convolution2D(filters=32, kernel_size=3, activation='relu')(inputs)\n",
        "dropout = keras.layers.Dropout(rate=0.24, activation='relu')(convolution)\n",
        "flattening = keras.layers.Flatten()(dropout)\n",
        "dense = keras.layers.Dense(units=32)(flattening)\n",
        "dropout_2 = keras.layers.Dropout(0.5)(dense)\n",
        "outputs = keras.layers.Dense(units=10, activation='softmax')(dropout_2)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huruvZgbDXb_"
      },
      "source": [
        "### Compile the model\n",
        "\n",
        "Select three key options\n",
        "1.   **optimizer**: the method for optimizing the weights. \"Stochastic Gradient Descent (SGD)\" is the canonical method.\n",
        "2.   **loss** function: the form of the function to encode the difference between the data's true label and the predict label.\n",
        "3.   **metric**: the function by which the model is evaluated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLaQvODcBzi2"
      },
      "outputs": [],
      "source": [
        "model.compile(  # complete"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLDD3Iy5D-UB"
      },
      "source": [
        "### Fit (read: Train) the model\n",
        "Use 5 epochs (batches) of 32 images and a validation split of 80%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYAh_2hODQTd"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "# complete\n",
        "# complete\n",
        "# complete\n",
        "# complete"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phnTXhesOdtT"
      },
      "source": [
        "## Diagnostics!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLR2O6j3F6k-"
      },
      "source": [
        "#### Evaluate overall model efficacy\n",
        "\n",
        "Evaluate model on training and test data and compare. This provides summary values that are equivalent to the final value in the accuracy plot below.  Don't forget to undo the one-hot encoding for the predicted labels *(hint: `np.argmax`)*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZdukNK27_jnm"
      },
      "outputs": [],
      "source": [
        "# complete\n",
        "# complete\n",
        "\n",
        "# complete\n",
        "# complete\n",
        "\n",
        "# complete\n",
        "# complete\n",
        "\n",
        "print(f'Train accuracy = {acc_train:.1%}')\n",
        "print(f'Test accuracy = {acc_test:.1%}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqD61qqNOqWa"
      },
      "source": [
        "#### Plot accuracy and loss as a function of epochs (equivalently training time)\n",
        "This information is stored in the `history` object you defined earlier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hH7SJntRDTtB"
      },
      "outputs": [],
      "source": [
        "# complete\n",
        "# complete\n",
        "# complete\n",
        "# complete\n",
        "# complete\n",
        "# complete"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEn4dyybOzy4"
      },
      "source": [
        "#### Confusion Matrix\n",
        "Plot a confusion matrix for the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuMtsloj227g"
      },
      "outputs": [],
      "source": [
        "# complete"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "bzY9nK-_LLC6",
        "Ppacy9UTzAJT",
        "asIjm01UzUiK",
        "tnva-KuHjLw0",
        "TbZq-vUT-hgd",
        "Po6px0oM-vdg",
        "huruvZgbDXb_",
        "mLDD3Iy5D-UB",
        "phnTXhesOdtT",
        "NLR2O6j3F6k-",
        "SPtsnJscR-oA",
        "kqD61qqNOqWa",
        "vEn4dyybOzy4",
        "Zu8T1uCEakHJ",
        "OTd7QtwwEEvt",
        "-IidJOUgbNGF",
        "SrVGalGatWaK",
        "qwubzWGWWD6E"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
